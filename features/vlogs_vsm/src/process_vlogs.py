#!/usr/bin/env python
"""
Annotate short Dutch cooling-service .mov clips with structured problem/triage/solution
metadata using Gemini 2.5 Pro video understanding.

This script processes videos from the vlogs_vsm directory and outputs structured JSONL
for RAG ingestion into Weaviate.

Requirements:
    pip install google-genai pydantic python-dotenv

Env:
    GOOGLE_API_KEY - Set in root .env file
"""

import os
import json
import time
import asyncio
from pathlib import Path
from typing import List, Literal, Optional, Dict
from dotenv import load_dotenv

from google import genai
from google.genai import types
from pydantic import BaseModel, Field


# Load environment from root .env
root_dir = Path(__file__).parent.parent.parent.parent
env_path = root_dir / ".env"
load_dotenv(env_path)


# ---------- Structured output schema (for RAG) ----------

class Step(BaseModel):
    """One logical step in the clip, with approximate timestamps (seconds)."""
    kind: Literal["problem", "triage", "solution"] = Field(
        description="Step type: 'problem', 'triage', or 'solution'."
    )
    title: str = Field(description="Short human-readable label.")
    description: str = Field(description="Wat er in deze stap gebeurt, in heldere koeltechnische taal (Nederlands).")
    start_time_s: Optional[float] = Field(
        default=None,
        description="Approximate start time of this step in seconds from video start."
    )
    end_time_s: Optional[float] = Field(
        default=None,
        description="Approximate end time of this step in seconds from video start."
    )


class CoolingCaseCore(BaseModel):
    """Semantic payload generated by Gemini; we add file refs in Python."""
    language: Optional[str] = Field(
        default=None,
        description="Gedetecteerde gesproken taalcode (bijv. 'nl' voor Nederlands)."
    )
    installation_type: Optional[str] = Field(
        default=None,
        description="Type koelinstallatie (bijv. 'supermarkt vriescel', 'luchtgekoelde condensing unit'). Laat op null als het type niet duidelijk is."
    )
    environment_context: Optional[str] = Field(
        default=None,
        description="Korte context over waar de installatie staat (bijv. 'kleine restaurantkeuken'). Laat op null als dit niet duidelijk is."
    )
    problem_summary: Optional[str] = Field(
        default=None,
        description="1-3 zinnen in het Nederlands die het initiële probleem / de klacht samenvatten."
    )
    root_cause: Optional[str] = Field(
        default=None,
        description="Waarschijnlijkste grondoorzaak zoals uit de video blijkt. Laat op null als de oorzaak niet expliciet of duidelijk is."
    )
    solution_summary: Optional[str] = Field(
        default=None,
        description="1-3 zinnen in het Nederlands die de uiteindelijke technische oplossing / fix samenvatten."
    )
    steps: List[Step] = Field(
        description="Ordered list of problem / triage / solution steps with approximate timestamps."
    )
    tags: Optional[List[str]] = Field(
        default=None,
        description="Korte Nederlandstalige tags voor RAG retrieval, bijv. ['lekkage detectie', 'expansieventiel', 'lage superheat']."
    )
    technical_components: Optional[List[str]] = Field(
        default=None,
        description="Lijst van specifieke koeltechnische componenten die worden genoemd (bijv. ['compressor', 'verdamper', 'expansieventiel']). Gebruik Nederlandstalige benamingen."
    )
    transcript: Optional[str] = Field(
        default=None,
        description="Een redelijk letterlijke Nederlandse transcriptie van de gesproken audio, of null als de audio onverstaanbaar is."
    )


# ---------- Prompt ----------

BASE_PROMPT = """
You are annotating a short training video for junior cooling / refrigeration technicians.
The video is in Dutch, and you MUST also answer in Dutch.

The expert in the video goes through three phases:
1) Problem description (what is wrong, symptoms, what the customer or system reports)
2) Triage / diagnostics (measurements, inspections, hypotheses, tests)
3) Solution / intervention (what is actually done to fix or stabilise the system)

TASK:
- If possible, infer the cooling installation type and environment context.
- Identify the main problem / complaint.
- Only identify a likely root cause if it is clearly supported by the video; otherwise leave `root_cause` as null.
- Extract a clean sequence of steps with approximate timestamps in SECONDS from video start.
- Classify each step as "problem", "triage", or "solution".
- Summarise the solution in crisp technical language.
- Extract all technical components mentioned (compressor, condenser, evaporator, valves, sensors, etc.)
- Add a fairly literal Dutch transcript of the spoken audio into the `transcript` field.
- The transcript should be as close to the spoken words as possible (within reason), in Dutch.

CONSTRAINTS:
- Output MUST strictly follow the provided JSON schema.
- Use concise, professional Dutch engineering language suitable for RAG.
- Do NOT guess the `installation_type` or `environment_context`; if they are not clearly inferable from the video, set them to null.
- Likewise, do NOT invent a `root_cause` if the video does not make it explicit; set `root_cause` to null in that case.
- Keep tags short, lower-case, and retrieval-friendly (e.g. 'lekkage detectie', 'verdamper ventilator', 'hogedrukschakelaar').
- Do not translate terms to English; keep all summaries, descriptions and tags in Dutch.
"""

SET_PROMPT = """
We are now working at the level of a *set* of 2–3 clips that belong to the same real-world service case.
You will receive a JSON array of clip-level records (including transcripts) previously produced with the CoolingCaseCore schema.

TASK:
- Synthesize ONE integrated case description that covers the whole set and output it again using the same CoolingCaseCore JSON schema.
- Reason across the clips to infer problem, triage and solution over the whole set.
- Be conservative about `installation_type`, `environment_context` and `root_cause`; only fill them if clearly supported by the combined evidence.
- Output must be in Dutch and follow the CoolingCaseCore schema exactly.

Set ID: {set_id}
Number of clips in set: {num_clips}
"""


# ---------- Helpers ----------

def parse_set_and_clip(stem: str) -> tuple[Optional[str], Optional[int]]:
    """
    Parse a filename stem like "A1_2" into a set_id and clip_index.

    Returns:
        (set_id, clip_index) or (None, None) if no underscore found.
    """
    if "_" in stem:
        parts = stem.split("_", 1)
        set_id = parts[0]
        try:
            clip_index = int(parts[1])
        except ValueError:
            clip_index = None
        return set_id, clip_index
    else:
        return None, None


# ---------- Core processing ----------

def build_client() -> genai.Client:
    """Build Gemini client using GOOGLE_API_KEY from environment."""
    api_key = os.environ.get("GOOGLE_API_KEY") or os.environ.get("GEMINI_API_KEY")
    if not api_key:
        raise RuntimeError(
            "Set GOOGLE_API_KEY in your .env file at project root.\n"
            f"Checked .env path: {env_path}"
        )
    return genai.Client(api_key=api_key)


def build_generation_config():
    """Structured-output config for our CoolingCaseCore schema."""
    return types.GenerateContentConfig(
        response_mime_type="application/json",
        response_schema=CoolingCaseCore,
    )


def process_video_file(
    client: genai.Client,
    video_path: Path,
    rag_blob_prefix: Optional[str] = None,
    set_id: Optional[str] = None,
    clip_index: Optional[int] = None,
    prior_payloads: Optional[List[dict]] = None,
) -> dict:
    """
    Upload one .mov, call Gemini 2.5 Pro, and return a dict ready for RAG storage.

    Returns a dict like:
    {
      "video_filename": ...,
      "video_local_path": ...,
      "gemini_file_uri": ...,
      "rag_blob_ref": ...,
      "payload": CoolingCaseCore(...)
      "record_kind": "clip",
      "set_id": set_id,
      "clip_index": clip_index,
      "transcript": core.transcript,
    }

    Args:
        prior_payloads: Optional list of payloads from earlier clips in the same set (for context).
    """
    print(f"Uploading {video_path.name} ...")

    # Upload video file to Gemini Files API
    uploaded_file = client.files.upload(file=str(video_path))

    # Wait for the file to be processed and become ACTIVE
    print(f"Processing {video_path.name}", end="", flush=True)
    while uploaded_file.state.name == "PROCESSING":
        print(".", end="", flush=True)
        time.sleep(5)
        uploaded_file = client.files.get(name=uploaded_file.name)

    if uploaded_file.state.name == "FAILED":
        raise ValueError(f"Video processing failed for {video_path.name}")

    print(" Ready!")

    # Where your actual binary blob will live for RAG (e.g. GCS, S3, local fs)
    if rag_blob_prefix:
        rag_blob_ref = f"{rag_blob_prefix.rstrip('/')}/{video_path.name}"
    else:
        rag_blob_ref = str(video_path)

    # Build prompt with uploaded video + optional context from earlier clips
    prompt = BASE_PROMPT
    if prior_payloads:
        prompt += (
            "\n\nCONTEXT UIT EERDERE CLIPS IN DEZELFDE SET:\n"
            "Je krijgt hieronder JSON-records van eerdere clips in dezelfde casus. "
            "Gebruik ze als aanvullende context, maar corrigeer expliciet als in de huidige clip "
            "iets anders blijkt.\n" +
            json.dumps(prior_payloads, ensure_ascii=False)
        )

    contents = [
        uploaded_file,
        prompt,
    ]

    cfg = build_generation_config()

    print(f"Calling Gemini 2.5 Pro for {video_path.name} ...")
    try:
        response = client.models.generate_content(
            model="gemini-2.5-pro",
            contents=contents,
            config=cfg,
        )

        # Parse structured output
        core = CoolingCaseCore.model_validate_json(response.text)

        return {
            "video_filename": video_path.name,
            "video_local_path": str(video_path),
            "gemini_file_uri": getattr(uploaded_file, "uri", None),
            "rag_blob_ref": rag_blob_ref,
            "payload": core.model_dump(),
            "record_kind": "clip",
            "set_id": set_id,
            "clip_index": clip_index,
            "transcript": core.transcript,
        }
    except Exception as e:
        print(f"Error processing {video_path.name}: {e}")
        raise


# Async wrapper for process_video_file
async def process_video_file_async(
    client: genai.Client,
    video_path: Path,
    rag_blob_prefix: Optional[str] = None,
    set_id: Optional[str] = None,
    clip_index: Optional[int] = None,
    prior_payloads: Optional[List[dict]] = None,
) -> dict:
    """Async wrapper around process_video_file for concurrent set-level processing."""
    return await asyncio.to_thread(
        process_video_file,
        client,
        video_path,
        rag_blob_prefix,
        set_id,
        clip_index,
        prior_payloads,
    )


def process_case_set(client: genai.Client, set_id: str, clip_records: List[dict]) -> dict:
    """
    Process a set of related clip records into one integrated case description.

    Returns a dict like:
    {
      "record_kind": "case_set",
      "set_id": set_id,
      "clip_filenames": [...],
      "payload": CoolingCaseCore(...)
    }
    """
    prompt_text = SET_PROMPT.format(set_id=set_id, num_clips=len(clip_records))
    contents = [
        prompt_text,
        json.dumps(clip_records, ensure_ascii=False),
    ]

    cfg = build_generation_config()

    print(f"Calling Gemini 2.5 Pro for set {set_id} ({len(clip_records)} clips) ...")
    try:
        response = client.models.generate_content(
            model="gemini-2.5-pro",
            contents=contents,
            config=cfg,
        )
        core = CoolingCaseCore.model_validate_json(response.text)
        return {
            "record_kind": "case_set",
            "set_id": set_id,
            "clip_filenames": [r["video_filename"] for r in clip_records],
            "payload": core.model_dump(),
        }
    except Exception as e:
        print(f"Error processing set {set_id}: {e}")
        raise


# Async wrapper for process_case_set
async def process_case_set_async(
    client: genai.Client,
    set_id: str,
    clip_records: List[dict],
) -> dict:
    """Async wrapper around process_case_set."""
    return await asyncio.to_thread(process_case_set, client, set_id, clip_records)



# Async implementation of process_directory
async def process_directory_async(
    videos_dir: str,
    output_path: str,
    rag_blob_prefix: Optional[str] = None,
    extensions=(".mov", ".mp4"),
    limit: Optional[int] = None,
):
    """
    Walk a directory, process all video files, and write JSONL for RAG ingestion.

    Clips belonging to the same set (e.g. A1_1, A1_2, A1_3) are processed *sequentially* in
    filename-index order, while different sets are processed *concurrently*.

    For each clip after the first in a set, the payloads of the earlier clips in that set are
    passed as context (`prior_payloads`) into the extraction prompt. After all clips in a set
    are processed, an additional aggregated `case_set` record is generated for that set.
    """
    client = build_client()
    out_file = Path(output_path)

    # Create output directory if it doesn't exist
    out_file.parent.mkdir(parents=True, exist_ok=True)

    # Find all video files
    video_paths = sorted(
        p for p in Path(videos_dir).glob("*")
        if p.suffix.lower() in extensions and p.is_file()
    )

    if not video_paths:
        raise RuntimeError(f"No video files with {extensions} found in {videos_dir}")

    # Apply limit if specified
    if limit:
        video_paths = video_paths[:limit]
        print(f"Processing {len(video_paths)} videos (limit applied)")

    print(f"Found {len(video_paths)} video(s) to process")

    # Group videos by set_id
    grouped: Dict[str, List[tuple[int, Path]]] = {}
    standalone: List[Path] = []

    for vp in video_paths:
        set_id, clip_index = parse_set_and_clip(vp.stem)
        if set_id is None:
            standalone.append(vp)
        else:
            idx = clip_index if clip_index is not None else 0
            grouped.setdefault(set_id, []).append((idx, vp))

    async def process_set(set_id: str, items: List[tuple[int, Path]]) -> List[dict]:
        # Ensure clips are in numeric order within the set
        items_sorted = sorted(items, key=lambda x: x[0])
        records: List[dict] = []

        for idx, vp in items_sorted:
            prior_payloads = [r["payload"] for r in records]
            print(f"Processing clip {vp.name} in set {set_id} (index {idx})...")
            rec = await process_video_file_async(
                client,
                vp,
                rag_blob_prefix=rag_blob_prefix,
                set_id=set_id,
                clip_index=idx,
                prior_payloads=prior_payloads,
            )
            records.append(rec)

        # After all clips in the set, produce an aggregated case_set record
        if len(records) >= 2:
            case_rec = await process_case_set_async(client, set_id, records)
            records.append(case_rec)

        return records

    async def process_single(vp: Path) -> List[dict]:
        print(f"Processing standalone clip {vp.name} (no set_id)...")
        rec = await process_video_file_async(
            client,
            vp,
            rag_blob_prefix=rag_blob_prefix,
            set_id=None,
            clip_index=None,
            prior_payloads=None,
        )
        return [rec]

    tasks = []
    for set_id, items in grouped.items():
        tasks.append(process_set(set_id, items))
    for vp in standalone:
        tasks.append(process_single(vp))

    all_records: List[dict] = []
    if tasks:
        results = await asyncio.gather(*tasks)
        for group_records in results:
            all_records.extend(group_records)

    # Sort records so that within a set all clip records come before the case_set
    def sort_key(rec: dict):
        set_id = rec.get("set_id") or ""
        kind = rec.get("record_kind") or "clip"
        clip_index = rec.get("clip_index")
        kind_order = 0 if kind == "clip" else 1
        ci = clip_index if isinstance(clip_index, int) else 0
        return (set_id, kind_order, ci)

    all_records_sorted = sorted(all_records, key=sort_key)

    with out_file.open("w", encoding="utf-8") as f:
        for rec in all_records_sorted:
            f.write(json.dumps(rec, ensure_ascii=False) + "\n")

    print(f"\nDone. Wrote {len(all_records_sorted)} JSONL records.")
    print(f"Output written to: {out_file}")


# Synchronous wrapper for process_directory_async
def process_directory(
    videos_dir: str,
    output_path: str,
    rag_blob_prefix: Optional[str] = None,
    extensions=(".mov", ".mp4"),
    limit: Optional[int] = None,
):
    """Synchronous wrapper around process_directory_async for CLI usage."""
    return asyncio.run(
        process_directory_async(
            videos_dir,
            output_path,
            rag_blob_prefix=rag_blob_prefix,
            extensions=extensions,
            limit=limit,
        )
    )


# ---------- CLI entrypoint ----------

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="Annotate Dutch cooling-service .mov clips with Gemini 2.5 Pro for RAG."
    )
    parser.add_argument(
        "videos_dir",
        nargs="?",
        default=None,
        help="Directory containing .mov/.mp4 clips. Defaults to features/vlogs_vsm/",
    )
    parser.add_argument(
        "--out",
        default=None,
        help="Output JSONL path. Defaults to features/vlogs_vsm/output/<input_dir>_annotations.jsonl",
    )
    parser.add_argument(
        "--rag-blob-prefix",
        default=None,
        help="Prefix for where video blobs will live for RAG "
             "(e.g. 'gs://my-bucket/cooling-clips'). "
             "We append the filename to this prefix.",
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=None,
        help="Limit number of videos to process (useful for testing)",
    )

    args = parser.parse_args()

    # Default to vlogs_vsm directory if not specified
    if args.videos_dir is None:
        script_dir = Path(__file__).parent.parent
        args.videos_dir = str(script_dir)

    # Default output path
    if args.out is None:
        videos_path = Path(args.videos_dir)
        output_dir = videos_path / "output"
        if videos_path.is_dir():
            base_name = videos_path.name
        else:
            base_name = videos_path.stem
        args.out = str(output_dir / f"{base_name}_annotations.jsonl")

    # Interactive prompt if no limit specified
    if args.limit is None:
        print("=" * 60)
        print("Video Processing Options")
        print("=" * 60)
        print("1. Process ONE video (A1_1.mov) - Quick test")
        print("2. Process ALL videos (15 total) - Full batch")
        print("=" * 60)

        while True:
            choice = input("Enter your choice (1 or 2): ").strip()
            if choice == "1":
                args.limit = 1
                print("\nProcessing 1 video (A1_1.mov)...\n")
                break
            elif choice == "2":
                args.limit = None
                print("\nProcessing all 15 videos...\n")
                break
            else:
                print("Invalid choice. Please enter 1 or 2.")

    print(f"Processing videos from: {args.videos_dir}")
    print(f"Output will be written to: {args.out}")
    print(f"Using .env from: {env_path}")
    print()

    process_directory(
        args.videos_dir,
        args.out,
        rag_blob_prefix=args.rag_blob_prefix,
        limit=args.limit,
    )
