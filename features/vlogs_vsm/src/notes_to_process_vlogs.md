Here’s a concrete Python script you can drop in as a first pass over your Dutch .mov “problem → triage → solution” clips using Gemini 2.5 Pro + video understanding + structured output.

It uses:
	•	google-genai SDK and Files API to upload each .mov  ￼
	•	JSON schema / Pydantic structured output for stable fields (problem, steps, solution, metadata)  ￼

#!/usr/bin/env python
"""
Annotate short cooling-service .mov clips with structured problem/triage/solution
metadata using Gemini 2.5 Pro video understanding.

Requirements:
    pip install google-genai pydantic

Env:
    export GEMINI_API_KEY="your-api-key"
"""

import os
import json
from pathlib import Path
from typing import List, Literal, Optional

from google import genai
from google.genai import types
from pydantic import BaseModel, Field


# ---------- Structured output schema (for RAG) ----------

class Step(BaseModel):
    """One logical step in the clip, with approximate timestamps (seconds)."""
    kind: Literal["problem", "triage", "solution"] = Field(
        description="Step type: 'problem', 'triage', or 'solution'."
    )
    title: str = Field(description="Short human-readable label.")
    description: str = Field(description="What happens in this step, in clear technical language.")
    start_time_s: Optional[float] = Field(
        default=None,
        description="Approximate start time of this step in seconds from video start."
    )
    end_time_s: Optional[float] = Field(
        default=None,
        description="Approximate end time of this step in seconds from video start."
    )


class CoolingCaseCore(BaseModel):
    """Semantic payload generated by Gemini; we add file refs in Python."""
    language: str = Field(
        description="Detected spoken language code (e.g. 'nl')."
    )
    installation_type: Optional[str] = Field(
        default=None,
        description="Type of cooling installation (e.g. 'supermarket walk-in freezer', 'air-cooled condensing unit')."
    )
    environment_context: Optional[str] = Field(
        default=None,
        description="Very short context about where the installation is located (e.g. 'small restaurant kitchen')."
    )
    problem_summary: str = Field(
        description="1–3 sentences summarising the initial problem / complaint."
    )
    root_cause: Optional[str] = Field(
        default=None,
        description="Most likely root cause as inferred from the clip."
    )
    solution_summary: str = Field(
        description="1–3 sentences summarising the final technical solution / fix."
    )
    steps: List[Step] = Field(
        description="Ordered list of problem / triage / solution steps with approximate timestamps."
    )
    tags: List[str] = Field(
        description="Short tags useful for RAG retrieval, e.g. ['leak detection', 'TXV', 'low superheat']."
    )


# ---------- Prompt ----------

BASE_PROMPT = """
You are annotating a short training video for junior cooling / refrigeration technicians.
The video is in Dutch, but you MUST answer in English.

The expert in the video goes through three phases:
1) Problem description (what is wrong, symptoms, what the customer or system reports)
2) Triage / diagnostics (measurements, inspections, hypotheses, tests)
3) Solution / intervention (what is actually done to fix or stabilise the system)

TASK:
- Infer the cooling installation type and environment context.
- Identify the main problem and likely root cause.
- Extract a clean sequence of steps with approximate timestamps in SECONDS from video start.
- Classify each step as "problem", "triage", or "solution".
- Summarise the solution in crisp technical language.

CONSTRAINTS:
- Output MUST strictly follow the provided JSON schema.
- Use concise engineering language suitable for RAG.
- Keep tags short, lower-case, and retrieval-friendly (e.g. 'leak detection', 'evaporator fan', 'pressure switch').
"""


# ---------- Core processing ----------

def build_client() -> genai.Client:
    api_key = os.environ.get("GEMINI_API_KEY") or os.environ.get("GOOGLE_API_KEY")
    if not api_key:
        raise RuntimeError("Set GEMINI_API_KEY or GOOGLE_API_KEY in your environment.")
    return genai.Client(api_key=api_key)


def build_generation_config():
    """Structured-output config for our CoolingCaseCore schema."""
    return {
        "response_mime_type": "application/json",
        "response_json_schema": CoolingCaseCore.model_json_schema(),
    }


def process_video_file(
    client: genai.Client,
    video_path: Path,
    rag_blob_prefix: Optional[str] = None,
) -> dict:
    """
    Upload one .mov, call Gemini 2.5 Pro, and return a dict ready for RAG storage.

    Returns a dict like:
    {
      "video_filename": ...,
      "video_local_path": ...,
      "gemini_file_uri": ...,
      "rag_blob_ref": ...,
      "payload": CoolingCaseCore(...)
    }
    """
    print(f"Uploading {video_path} ...")
    uploaded = client.files.upload(file=str(video_path))  # File API, mime-type auto-detected  [oai_citation:2‡Google AI for Developers](https://ai.google.dev/gemini-api/docs/video-understanding)

    # Where your actual binary blob will live for RAG (e.g. GCS, S3, local fs).
    # For now we just use a prefix + filename; you can later mirror that to GCS/S3.
    if rag_blob_prefix:
        rag_blob_ref = f"{rag_blob_prefix.rstrip('/')}/{video_path.name}"
    else:
        rag_blob_ref = str(video_path)

    contents = [
        uploaded,
        types.Part.from_text(BASE_PROMPT),
    ]

    cfg = build_generation_config()

    print(f"Calling Gemini 2.5 Pro for {video_path.name} ...")
    resp = client.models.generate_content(
        model="gemini-2.5-pro",  # same pattern as docs, but Pro instead of Flash  [oai_citation:3‡Google AI for Developers](https://ai.google.dev/gemini-api/docs/models?utm_source=chatgpt.com)
        contents=contents,
        config=cfg,
    )

    core = CoolingCaseCore.model_validate_json(resp.text)

    return {
        "video_filename": video_path.name,
        "video_local_path": str(video_path),
        "gemini_file_uri": getattr(uploaded, "uri", None),
        "rag_blob_ref": rag_blob_ref,
        "payload": core.model_dump(),
    }


def process_directory(
    videos_dir: str,
    output_path: str,
    rag_blob_prefix: Optional[str] = None,
    extensions=(".mov", ".mp4"),
):
    """
    Walk a directory, process all video files, and write JSONL for RAG ingestion.
    Each line = one annotated clip (dict from process_video_file).
    """
    client = build_client()
    out_file = Path(output_path)

    video_paths = sorted(
        p for p in Path(videos_dir).glob("**/*")
        if p.suffix.lower() in extensions and p.is_file()
    )

    if not video_paths:
        raise RuntimeError(f"No video files with {extensions} found under {videos_dir}")

    with out_file.open("w", encoding="utf-8") as f:
        for vp in video_paths:
            record = process_video_file(client, vp, rag_blob_prefix=rag_blob_prefix)
            f.write(json.dumps(record, ensure_ascii=False) + "\n")
            print(f"✓ Annotated {vp.name}")

    print(f"\nDone. Wrote {len(video_paths)} records to {out_file}")


# ---------- CLI entrypoint ----------

if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(
        description="Annotate cooling-service .mov clips with Gemini 2.5 Pro for RAG."
    )
    parser.add_argument("videos_dir", help="Directory containing .mov/.mp4 clips.")
    parser.add_argument(
        "--out",
        default="cooling_clips_annotations.jsonl",
        help="Output JSONL path (one record per video).",
    )
    parser.add_argument(
        "--rag-blob-prefix",
        default=None,
        help="Prefix for where video blobs will live for RAG "
             "(e.g. 'gs://my-bucket/cooling-clips'). "
             "We append the filename to this prefix.",
    )

    args = parser.parse_args()
    process_directory(args.videos_dir, args.out, rag_blob_prefix=args.rag_blob_prefix)

How this fits your RAG setup:
	•	Each line in cooling_clips_annotations.jsonl is a clean, schema-validated record with:
	•	rag_blob_ref: where your binary lives (GCS/S3/local), ready to be attached as a file reference in your RAG agent.
	•	payload.steps: ordered problem → triage → solution with timestamps for clickable jumps.
	•	payload.tags, problem_summary, solution_summary: nice keys for indexing and retrieval.

You can now feed payload into your vector / keyword index, and keep rag_blob_ref + gemini_file_uri around for re-attaching the original video when the agent surfaces a case.