# Current State Query - Information Flow Analysis

**Date**: November 12, 2025  
**Diagram**: `current_state_info_flow.mermaid`  
**Status**: Documents planned vs actual behavior

---

## Executive Summary

When a user asks "What's the current state?", the system **should** respond in <200ms with a concise sensor summary. Currently, it takes **2-3 minutes** and returns irrelevant diagrams because the fast-path tool (`get_current_status`) is **not yet implemented**.

---

## Information Flow - Layer by Layer

### Layer 1: Frontend â†’ Backend (WebSocket)

**File**: `elysia/api/routes/query.py`

```python
async def process(data: dict, websocket: WebSocket, user_manager: UserManager):
    # User query arrives as WebSocket message
    {
        "user_id": "user_123",
        "conversation_id": "conv_456", 
        "query": "What's the current state?",
        "query_id": "q_789"
    }
```

**Flow**:
1. User types query in frontend
2. WebSocket client sends JSON message
3. `process()` function receives message
4. Sends NER response (named entity recognition)
5. Calls `user_manager.process_tree()`

**Timing**: ~10ms (network latency)

---

### Layer 2: User Manager â†’ Tree Manager

**File**: `elysia/api/services/user.py`

```python
async def process_tree(self, query: str, user_id: str, conversation_id: str, ...):
    # 1. Check user timeout
    if self.check_user_timeout(user_id):
        yield UserTimeoutError()
        return
    
    # 2. Get local user (tree manager, client manager, config)
    local_user = await self.get_user_local(user_id)
    tree_manager: TreeManager = local_user["tree_manager"]
    
    # 3. Forward to tree manager
    async for yielded_result in tree_manager.process_tree(...):
        yield yielded_result
```

**Flow**:
1. Validate user not timed out
2. Validate tree not timed out (or reload from Weaviate)
3. Get TreeManager for this user
4. Stream results back to WebSocket

**Timing**: ~20ms (validation + lookup)

---

### Layer 3: Tree Manager â†’ Tree

**File**: `elysia/api/services/tree.py`

```python
async def process_tree(self, query: str, conversation_id: str, ...):
    # 1. Get tree for this conversation
    tree: Tree = self.get_tree(conversation_id)
    
    # 2. Wait for tree to be idle (async lock)
    await self.trees[conversation_id]["event"].wait()
    
    # 3. Mark tree as working
    self.trees[conversation_id]["event"].clear()
    
    # 4. Run tree
    async for yielded_result in tree.async_run(query, ...):
        yield yielded_result
    
    # 5. Mark tree as idle again
    self.trees[conversation_id]["event"].set()
```

**Flow**:
1. Retrieve tree from in-memory dict
2. Async lock (prevent concurrent requests)
3. Execute tree
4. Release lock

**Timing**: ~10ms (lock overhead)

---

### Layer 4: Tree Execution Engine

**File**: `elysia/tree/tree.py`

```python
async def async_run(self, user_prompt: str, ...):
    # 1. Append user query to conversation history
    self.tree_data.conversation_history.append({
        "role": "user",
        "content": user_prompt
    })
    
    # 2. Find current branch (starts at root)
    current_node = self.decision_nodes[self.root]  # "smido_melding"
    
    # 3. Iterate until end_actions=True
    while not end_actions:
        # 4. Check which tools are available
        available_tools = [
            tool_id for tool_id in current_node.options 
            if tool.is_tool_available(...)
        ]
        
        # 5. Call DecisionNode to choose tool
        decision, yielded_items = await current_node(
            tree_data=self.tree_data,
            base_lm=self.base_lm,
            available_tools=available_tools,
            ...
        )
        
        # 6. Execute chosen tool
        async for result in self._execute_tool(decision):
            yield result
        
        # 7. Move to next node or finish
        if decision.end_actions:
            break
        current_node = self._get_next_node(decision)
```

**Flow**:
1. Add user query to history
2. Start at root node (`smido_melding`)
3. Loop: Choose tool â†’ Execute â†’ Move to next node
4. Yield Status/Result objects to frontend

**Timing**: Variable (depends on LLM + tools)

---

### Layer 5: LLM Decision Making

**File**: `elysia/tree/util.py` (DecisionNode)

```python
async def __call__(self, tree_data, base_lm, available_tools, ...):
    # 1. Format available tools for LLM
    available_options = self._options_to_json(available_tools)
    # {
    #   "get_alarms": {
    #     "function_name": "get_alarms",
    #     "description": "Query active alarms...",
    #     "inputs": {...}
    #   },
    #   "get_asset_health": {...},
    #   "get_current_status": {...}  # PLANNED, not yet implemented
    # }
    
    # 2. Create decision prompt
    decision_module = ElysiaChainOfThought(
        DecisionPrompt,
        tree_data=tree_data,
        environment=True,
        ...
    )
    
    # 3. LLM decides which tool to call
    with dspy.context(lm=base_lm):
        decision = decision_module(
            user_prompt=tree_data.conversation_history[-1],
            available_actions=available_options,
            agent_description=tree_data.atlas.agent_description,
            instruction=self.instruction,  # M branch instruction
            ...
        )
    
    return decision
```

**Prompt sent to LLM** (simplified):

```
You are a Virtual Service Mechanic guiding a junior technician.

Current phase: MELDING (Symptom collection)

Instruction:
Je bent in de MELDING fase - eerste contact met de monteur.
KRITISCH: FAST PATH FIRST
DETECTEER USER INTENT:
1. STATUS CHECK â†’ Gebruik ALLEEN get_current_status

Available actions:
- get_alarms: Query active alarms and severity
- get_asset_health: Compare WorldState vs Context (W vs C)
- get_current_status: Quick status summary (5 sensors + flags)  [PLANNED]

User: What's the current state?

Choose the best tool and provide reasoning.
```

**LLM Response** (planned):

```json
{
  "function_name": "get_current_status",
  "reasoning": "User asking for current state - fast path tool",
  "function_inputs": {
    "asset_id": "135_1570",
    "timestamp": null
  }
}
```

**LLM Response** (current, fallback):

```json
{
  "function_name": "get_asset_health",
  "reasoning": "User asking about current state - need sensor data",
  "function_inputs": {
    "asset_id": "135_1570",
    "timestamp": null,
    "window_minutes": 60
  }
}
```

**Timing**: 
- Fast path (cached decision): ~100ms
- Slow path (first time): ~500ms

---

### Layer 6: Tool Execution

#### 6A. Planned: get_current_status (FAST PATH)

**File**: `elysia/api/custom_tools.py` (NOT YET IMPLEMENTED)

```python
@tool(status="Retrieving current status...", branch_id="smido_melding")
async def get_current_status(
    asset_id: str,
    timestamp: str = None,
    tree_data=None,
    **kwargs
):
    """Quick status summary - reads from pre-seeded cache."""
    yield Status("Reading cached WorldState...")
    
    # Read from cache (pre-seeded at tree startup)
    if hasattr(tree_data._tree, '_initial_worldstate_cache'):
        worldstate = tree_data._tree._initial_worldstate_cache
    else:
        # Fallback: generate synthetic "today"
        from features.telemetry_vsm.src.worldstate_engine import WorldStateEngine
        engine = WorldStateEngine("features/telemetry/...")
        worldstate = engine.compute_worldstate(asset_id, datetime.now(), 60)
    
    # Extract concise summary
    current = worldstate.get('current_state', {})
    flags = worldstate.get('flags', {})
    health = worldstate.get('health_scores', {})
    
    summary = {
        "room_temp": current.get('current_room_temp'),
        "hot_gas_temp": current.get('current_hot_gas_temp'),
        "suction_temp": current.get('current_suction_temp'),
        "liquid_temp": current.get('current_liquid_temp'),
        "ambient_temp": current.get('current_ambient_temp'),
        "active_flags": [k for k, v in flags.items() if v],
        "cooling_health": health.get('cooling_system_health'),
        "compressor_health": health.get('compressor_health'),
        "stability_health": health.get('stability_health'),
    }
    
    yield Result(objects=[summary], metadata={"source": "cache"})
```

**Data Flow**: Cache â†’ Extract â†’ Format â†’ Yield

**Timing**: <1ms (in-memory read)

#### 6B. Current: get_asset_health (SLOW PATH)

**File**: `elysia/api/custom_tools.py` (lines 645-820)

```python
@tool(status="Analyzing asset health...", branch_id="smido_melding")
async def get_asset_health(
    asset_id: str,
    timestamp: str = None,
    window_minutes: int = 60,
    tree_data=None,
    client_manager=None,
    **kwargs
):
    """Compare W vs C - balance check."""
    yield Status("Computing WorldState...")
    
    # 1. Read parquet file (SLOW)
    from features.telemetry_vsm.src.worldstate_engine import WorldStateEngine
    engine = WorldStateEngine("features/telemetry/...")
    worldstate = engine.compute_worldstate(asset_id, timestamp, window_minutes)
    # â†’ Reads 785K rows from disk (~800ms)
    
    yield Status("Loading commissioning data...")
    
    # 2. Load Context (C) from JSON file
    with open("features/integration_vsm/output/fd_assets_enrichment.json") as f:
        context = json.load(f)
    # â†’ Disk I/O (~50ms)
    
    yield Status("Comparing W vs C...")
    
    # 3. Compare WorldState (W) vs Context (C)
    comparison = {
        "current_vs_design": {...},
        "out_of_balance_factors": [...],
        "health_summary": {...}
    }
    
    yield Result(objects=[comparison], metadata={"source": "w_vs_c"})
```

**Data Flow**: Parquet â†’ Compute â†’ JSON â†’ Compare â†’ Yield

**Timing**: ~1200ms (parquet read + computation)

**Problem**: This is a **diagnostic tool**, not a **status tool**. Overkill for "What's the current state?"

#### 6C. Extra: search_manuals_by_smido (UNNECESSARY)

After get_asset_health, LLM sometimes decides to call `search_manuals_by_smido`:

```python
@tool(status="Searching manuals...", branch_id="smido_installatie")
async def search_manuals_by_smido(
    query: str = "",
    smido_step: str = None,
    ...
):
    # Queries Weaviate VSM_ManualSections + VSM_Diagram
    # Returns manual sections + diagrams
```

**Timing**: ~600ms (Weaviate query)

**Problem**: User didn't ask for manuals! This is **unnecessary** for a status query.

---

### Layer 7: Results Formatting & Streaming

**File**: `elysia/objects.py` + `elysia/tree/util.py`

Each tool yields `Status` and `Result` objects:

```python
# Status object (progress indicator)
Status("Computing WorldState...")
â†’ {
    "type": "status",
    "payload": {"text": "Computing WorldState..."},
    "user_id": "user_123",
    "conversation_id": "conv_456",
    "query_id": "q_789"
}

# Result object (data)
Result(objects=[worldstate_summary], metadata={"source": "w_vs_c"})
â†’ {
    "type": "result",
    "payload": {
        "objects": [{...}],
        "metadata": {"source": "w_vs_c"}
    },
    "user_id": "user_123",
    "conversation_id": "conv_456",
    "query_id": "q_789"
}
```

These are streamed back through:
- Tree.async_run() â†’ yields to
- TreeManager.process_tree() â†’ yields to
- UserManager.process_tree() â†’ yields to
- WebSocket endpoint â†’ sends JSON to
- Frontend

**Timing**: ~10ms per message (serialization + network)

---

## Complete Timing Breakdown

### Planned Fast Path (get_current_status implemented)

| Step | Component | Time | Cumulative |
|------|-----------|------|------------|
| 1 | WebSocket â†’ API | 10ms | 10ms |
| 2 | User Manager validation | 20ms | 30ms |
| 3 | Tree Manager lock | 10ms | 40ms |
| 4 | Tree setup | 10ms | 50ms |
| 5 | LLM decision (cached) | 100ms | 150ms |
| 6 | **get_current_status (cache read)** | **<1ms** | **151ms** |
| 7 | Format response | 10ms | 161ms |
| 8 | WebSocket send | 10ms | 171ms |
| **TOTAL** | | | **~170ms** âœ… |

### Current Slow Path (fallback to diagnostics)

| Step | Component | Time | Cumulative |
|------|-----------|------|------------|
| 1 | WebSocket â†’ API | 10ms | 10ms |
| 2 | User Manager validation | 20ms | 30ms |
| 3 | Tree Manager lock | 10ms | 40ms |
| 4 | Tree setup | 10ms | 50ms |
| 5 | LLM decision #1 | 500ms | 550ms |
| 6 | **get_asset_health (parquet read)** | **800ms** | **1350ms** |
| 7 | **WorldState computation** | **400ms** | **1750ms** |
| 8 | **W vs C comparison** | **50ms** | **1800ms** |
| 9 | LLM decision #2 (unnecessary) | 500ms | 2300ms |
| 10 | **search_manuals (Weaviate)** | **600ms** | **2900ms** |
| 11 | Format response | 50ms | 2950ms |
| 12 | WebSocket send | 10ms | 2960ms |
| **TOTAL** | | | **~3 seconds** âŒ |

---

## Root Cause Analysis

### Why is get_current_status not working?

**Answer**: **It's not implemented yet.**

**Evidence**:
```bash
$ grep -n "get_current_status" elysia/api/custom_tools.py
# No matches found
```

**Documentation says** (from `docs/QUICK_STATUS_IMPLEMENTATION.md`):

> **File**: `elysia/api/custom_tools.py` (lines 49-178)
>
> **Key features**:
> - Reads from `tree._initial_worldstate_cache` (pre-seeded at startup)

**But in reality**:
- Lines 49-178 in `custom_tools.py` contain `search_manuals_by_smido`, not `get_current_status`
- The tool is **planned** but **not yet coded**

### Why does the system fall back to slow tools?

When LLM tries to choose `get_current_status`:

1. DecisionNode checks `available_tools`
2. `get_current_status` not in tools dict â†’ filtered out
3. LLM only sees: `get_alarms`, `get_asset_health`
4. LLM chooses `get_asset_health` (closest match)
5. Cascades into diagnostic workflow

### Why does it search manuals?

After `get_asset_health` completes:

1. LLM sees "out of balance factors" in results
2. M branch instruction says: "Use SearchManualsBySMIDO for relevant sections"
3. LLM decides to provide context â†’ calls `search_manuals_by_smido`
4. Returns diagrams user didn't ask for

---

## Required Implementation

### 1. Create get_current_status tool

**File**: `elysia/api/custom_tools.py`

Add after line 47 (before `search_manuals_by_smido`):

```python
@tool(
    status="Retrieving current status...",
    branch_id="smido_melding"
)
async def get_current_status(
    asset_id: str,
    timestamp: str = None,
    tree_data=None,
    **kwargs
):
    """
    Quick status check - returns concise sensor summary.
    
    When to use:
    - User asks: "What's the current state?", "How are we doing?", "Status?"
    - M phase: Quick overview before diagnosis
    
    When NOT to use:
    - Deep diagnosis needed â†’ use get_asset_health
    - Historical analysis â†’ use compute_worldstate
    
    What it returns:
    - 5 key sensors (room, hot gas, suction, liquid, ambient)
    - Active flags
    - Health scores
    - Trend (rising/falling/stable)
    
    How to explain to M:
    "Huidige status (timestamp):
      â€¢ Koelcel temperatuur: XÂ°C (design: YÂ°C)
      â€¢ Heetgas: XÂ°C
      â€¢ Zuigdruk: XÂ°C
      â€¢ Actieve flags: [list]
      
    Wil je dat ik een diagnose start?"
    
    Performance: <100ms (reads from pre-seeded cache)
    """
    yield Status("Reading cached WorldState...")
    
    # Check for pre-seeded cache
    if hasattr(tree_data, '_tree') and hasattr(tree_data._tree, '_initial_worldstate_cache'):
        worldstate = tree_data._tree._initial_worldstate_cache
    else:
        # Fallback: generate synthetic "today"
        from features.telemetry_vsm.src.worldstate_engine import WorldStateEngine
        from datetime import datetime
        
        engine = WorldStateEngine("features/telemetry/timeseries_freezerdata/135_1570_cleaned_with_flags.parquet")
        now = datetime.now()
        worldstate = engine.compute_worldstate(asset_id, now, 60)
    
    # Extract concise summary
    current = worldstate.get('current_state', {})
    flags = worldstate.get('flags', {})
    trends = worldstate.get('trends_30m', {})
    health = worldstate.get('health_scores', {})
    
    active_flags = [k.replace('flag_', '') for k, v in flags.items() if v]
    
    # Determine trend
    room_temp_trend = trends.get('room_temp_change_30m', 0)
    if abs(room_temp_trend) < 0.5:
        trend = "stabiel"
    elif room_temp_trend > 0:
        trend = f"stijgend (+{room_temp_trend:.1f}Â°C)"
    else:
        trend = f"dalend ({room_temp_trend:.1f}Â°C)"
    
    summary = {
        "timestamp": worldstate.get('timestamp'),
        "sensors": {
            "room_temp": current.get('current_room_temp'),
            "hot_gas_temp": current.get('current_hot_gas_temp'),
            "suction_temp": current.get('current_suction_temp'),
            "liquid_temp": current.get('current_liquid_temp'),
            "ambient_temp": current.get('current_ambient_temp'),
        },
        "active_flags": active_flags,
        "trend": trend,
        "health_scores": {
            "cooling": health.get('cooling_system_health'),
            "compressor": health.get('compressor_health'),
            "stability": health.get('stability_health'),
        },
        "is_synthetic_today": worldstate.get('is_synthetic_today', False)
    }
    
    yield Result(objects=[summary], metadata={
        "source": "worldstate_cache",
        "performance": "fast_path"
    })
```

### 2. Pre-seed cache at tree startup

**File**: `features/vsm_tree/bootstrap.py`

Update `vsm_smido_bootstrap()` function (after line 139):

```python
def vsm_smido_bootstrap(tree: Tree, context: Dict[str, Any]) -> None:
    """Bootstrap VSM SMIDO tree structure."""
    logger.info("Bootstrapping VSM SMIDO tree structure...")
    
    # Add SMIDO branches
    _add_m_branch(tree)
    _add_t_branch(tree)
    _add_i_branch(tree)
    _add_d_branch(tree)
    _add_o_branch(tree)
    
    # Assign tools
    _assign_tools_to_branches(tree)
    
    # âœ¨ NEW: Pre-seed WorldState cache
    logger.info("Pre-seeding WorldState cache...")
    from features.telemetry_vsm.src.worldstate_engine import WorldStateEngine
    from datetime import datetime
    
    engine = WorldStateEngine("features/telemetry/timeseries_freezerdata/135_1570_cleaned_with_flags.parquet")
    now = datetime.now()
    
    # Generate synthetic "today" WorldState
    worldstate = engine.compute_worldstate("135_1570", now, 60)
    
    # Store in tree
    tree._initial_worldstate_cache = worldstate
    
    logger.info(f"WorldState cache pre-seeded (timestamp: {worldstate['timestamp']})")
    logger.info("VSM SMIDO tree structure bootstrapped successfully")
```

### 3. Add tool to M branch

**File**: `features/vsm_tree/smido_tree.py`

Update `_assign_tools_to_branches()` function (around line 537):

```python
def _assign_tools_to_branches(tree: Tree):
    """Assign tools to appropriate SMIDO branches."""
    from elysia.api.custom_tools import (
        get_current_status,  # âœ¨ NEW
        get_alarms,
        get_asset_health,
        compute_worldstate,
        query_telemetry_events,
        search_manuals_by_smido,
        query_vlog_cases,
        analyze_sensor_pattern
    )
    
    # M - Melding: Quick status FIRST (fast path)
    tree.add_tool(get_current_status, branch_id="smido_melding")  # âœ¨ Priority #1
    tree.add_tool(get_alarms, branch_id="smido_melding")
    tree.add_tool(get_asset_health, branch_id="smido_melding")
    
    # ... rest of tools
```

### 4. Update M branch instructions

**File**: `features/vsm_tree/smido_tree.py`

Update `_add_m_branch()` function (lines 105-141) to emphasize fast path:

```python
def _add_m_branch(tree: Tree):
    """M - MELDING: Symptom collection"""
    tree.add_branch(
        branch_id="smido_melding",
        instruction="""Je bent in de MELDING fase - eerste contact met de monteur.

**KRITISCH: FAST PATH FIRST**

DETECTEER USER INTENT:

1. **STATUS CHECK** â†’ Gebruik ALLEEN get_current_status
   Vragen zoals: "What's the current state?", "Hoe gaat het?", "Status?"
   â†’ Antwoord: Concise overzicht (5 sensors + flags)
   â†’ Vraag MAX Ã‰Ã‰N vervolg: "Wil je diagnose?"
   â†’ STOP. Ga NIET automatisch door naar T/I/D
   
2. **STORING MELDING** â†’ get_alarms â†’ get_asset_health
   Vragen zoals: "Er is een probleem", "Alarm afgegaan"
   â†’ Verzamel symptomen, ga door naar T
   
3. **DIAGNOSE VRAAG** â†’ Start volledige SMIDO workflow
   Vragen zoals: "Waarom werkt het niet?", "Wat is de oorzaak?"
   â†’ Volledige Mâ†’Tâ†’Iâ†’Dâ†’O flow

... (rest of instruction)
""",
        description="Collect symptoms and assess urgency",
        root=True,
        status="Verzamel symptomen..."
    )
```

---

## Testing the Fix

### Test Script

```python
# scripts/test_current_status_fast_path.py

from features.vsm_tree.smido_tree import create_vsm_tree
import asyncio
import time

async def test_fast_path():
    # Create tree with bootstrapper
    tree = create_vsm_tree(with_orchestrator=False)
    
    # Verify cache is pre-seeded
    assert hasattr(tree, '_initial_worldstate_cache'), "Cache not pre-seeded!"
    print(f"âœ… Cache pre-seeded: {tree._initial_worldstate_cache['timestamp']}")
    
    # Verify get_current_status tool exists
    m_node = tree.decision_nodes['smido_melding']
    assert 'get_current_status' in m_node.options, "get_current_status not in M branch!"
    print(f"âœ… get_current_status tool registered")
    
    # Simulate user query
    start = time.time()
    
    # This should call get_current_status (fast path)
    results = []
    async for result in tree.async_run("What's the current state?"):
        results.append(result)
    
    elapsed = time.time() - start
    
    # Verify performance
    assert elapsed < 0.5, f"Too slow! Took {elapsed:.2f}s (expected <500ms)"
    print(f"âœ… Response time: {elapsed*1000:.0f}ms")
    
    # Verify correct tool was called
    # (Check tree history or action_information)
    called_tools = [r for r in results if r.get('type') == 'status']
    assert any('get_current_status' in str(r) for r in called_tools), \
        "get_current_status not called! Fell back to slow path."
    print(f"âœ… Fast path used (get_current_status)")
    
    print("\nðŸŽ‰ ALL TESTS PASSED")

if __name__ == "__main__":
    asyncio.run(test_fast_path())
```

Run:
```bash
source .venv/bin/activate
python3 scripts/test_current_status_fast_path.py
```

Expected output:
```
âœ… Cache pre-seeded: 2025-11-12T17:30:00
âœ… get_current_status tool registered
âœ… Response time: 150ms
âœ… Fast path used (get_current_status)

ðŸŽ‰ ALL TESTS PASSED
```

---

## Summary

### Current State

```
User: "What's the current state?"
  â†“
LLM sees: [get_alarms, get_asset_health]  â† get_current_status missing!
  â†“
LLM chooses: get_asset_health (closest match)
  â†“
Tool reads parquet (800ms) + computes (400ms) = 1200ms
  â†“
LLM decides to search manuals (600ms) â† unnecessary!
  â†“
Total: 2-3 minutes âŒ
```

### Fixed State

```
User: "What's the current state?"
  â†“
LLM sees: [get_current_status, get_alarms, get_asset_health]  â† NEW!
  â†“
M branch instruction: "STATUS CHECK â†’ use get_current_status"
  â†“
LLM chooses: get_current_status (fast path)
  â†“
Tool reads cache (<1ms) â† pre-seeded at startup
  â†“
Returns 5 sensors + flags + trend
  â†“
Asks: "Wil je diagnose?"
  â†“
STOPS (doesn't auto-route to T/I/D)
  â†“
Total: ~150ms âœ…
```

### Files to Modify

1. **elysia/api/custom_tools.py** - Add `get_current_status` tool
2. **features/vsm_tree/bootstrap.py** - Pre-seed cache at startup
3. **features/vsm_tree/smido_tree.py** - Add tool to M branch + update instructions
4. **scripts/test_current_status_fast_path.py** - Verification test

### Impact

- **Performance**: 2-3 minutes â†’ <200ms (17x faster)
- **User experience**: Concise summary instead of overwhelming data
- **Intent detection**: System respects "status" vs "diagnosis" distinction
- **Zero breaking changes**: Diagnostic tools still work for deep analysis

